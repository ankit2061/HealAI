{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 409\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m     document_text = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[33m    DISCHARGE SUMMARY\u001b[39m\n\u001b[32m    389\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    406\u001b[39m \u001b[33m    Review after 2 weeks with fasting blood glucose report and BP monitoring chart.\u001b[39m\n\u001b[32m    407\u001b[39m \u001b[33m    \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     summarizer = \u001b[43mMedicalDocumentSummarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m     \u001b[38;5;66;03m# Generate plain text summary\u001b[39;00m\n\u001b[32m    412\u001b[39m     plain_summary = summarizer.summarize(document_text, document_type=\u001b[33m\"\u001b[39m\u001b[33mdischarge\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 173\u001b[39m, in \u001b[36mMedicalDocumentSummarizer.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    172\u001b[39m     \u001b[38;5;66;03m# Initialize the document parser\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     \u001b[38;5;28mself\u001b[39m.parser = \u001b[43mMedicalDocumentParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;66;03m# Initialize NLP summarization pipeline\u001b[39;00m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.summarizer = pipeline(\u001b[33m\"\u001b[39m\u001b[33msummarization\u001b[39m\u001b[33m\"\u001b[39m, model=\u001b[33m\"\u001b[39m\u001b[33mfacebook/bart-large-cnn\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mMedicalDocumentParser.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Load NLP models\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28mself\u001b[39m.nlp = \u001b[43mspacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43men_core_web_md\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Initialize regex patterns for different document sections\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mself\u001b[39m.section_patterns = {\n\u001b[32m     15\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpatient_info\u001b[39m\u001b[33m\"\u001b[39m: re.compile(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(?:Patient Information|Patient Details|Personal Details)(?:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*:)?(.*?)(?=\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*[A-Z]|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mZ)\u001b[39m\u001b[33m\"\u001b[39m, re.DOTALL),\n\u001b[32m     16\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdiagnosis\u001b[39m\u001b[33m\"\u001b[39m: re.compile(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(?:Diagnosis|Clinical Impression|Assessment)(?:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*:)?(.*?)(?=\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms*[A-Z]|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mZ)\u001b[39m\u001b[33m\"\u001b[39m, re.DOTALL),\n\u001b[32m     17\u001b[39m         \u001b[38;5;66;03m# Add more patterns for other sections\u001b[39;00m\n\u001b[32m     18\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter_env/lib/python3.11/site-packages/spacy/__init__.py:51\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     28\u001b[39m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m     29\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] = util.SimpleFrozenDict(),\n\u001b[32m     35\u001b[39m ) -> Language:\n\u001b[32m     36\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m \u001b[33;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniconda/base/envs/jupyter_env/lib/python3.11/site-packages/spacy/util.py:472\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E050.format(name=name))\n",
      "\u001b[31mOSError\u001b[39m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from typing import Dict, List, Optional\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "\n",
    "class MedicalDocumentParser:\n",
    "    \"\"\"Class for parsing different types of medical documents\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Load NLP models\n",
    "        self.nlp = spacy.load(\"en_core_web_md\")\n",
    "        # Initialize regex patterns for different document sections\n",
    "        self.section_patterns = {\n",
    "            \"patient_info\": re.compile(r\"(?:Patient Information|Patient Details|Personal Details)(?:\\s*:)?(.*?)(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z)\", re.DOTALL),\n",
    "            \"diagnosis\": re.compile(r\"(?:Diagnosis|Clinical Impression|Assessment)(?:\\s*:)?(.*?)(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z)\", re.DOTALL),\n",
    "            # Add more patterns for other sections\n",
    "        }\n",
    "    \n",
    "    def parse_document(self, document_text: str, document_type: str = \"discharge\") -> Dict:\n",
    "        \"\"\"\n",
    "        Parse the document text into structured sections\n",
    "        \n",
    "        Args:\n",
    "            document_text: Raw text of the medical document\n",
    "            document_type: Type of document (discharge, claim, etc.)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing structured document sections\n",
    "        \"\"\"\n",
    "        # Process document with NLP\n",
    "        doc = self.nlp(document_text)\n",
    "        \n",
    "        # Extract sections based on document type\n",
    "        if document_type == \"discharge\":\n",
    "            return self._parse_discharge_summary(document_text, doc)\n",
    "        elif document_type == \"claim\":\n",
    "            return self._parse_claim_document(document_text, doc)\n",
    "        else:\n",
    "            return self._parse_generic_medical_document(document_text, doc)\n",
    "    \n",
    "    def _parse_discharge_summary(self, text: str, doc) -> Dict:\n",
    "        \"\"\"Parse discharge summary into structured sections\"\"\"\n",
    "        sections = {}\n",
    "        \n",
    "        # Extract patient information\n",
    "        patient_match = self.section_patterns[\"patient_info\"].search(text)\n",
    "        if patient_match:\n",
    "            sections[\"patient_info\"] = self._extract_patient_details(patient_match.group(1))\n",
    "        \n",
    "        # Extract diagnosis\n",
    "        diagnosis_match = self.section_patterns[\"diagnosis\"].search(text)\n",
    "        if diagnosis_match:\n",
    "            sections[\"diagnosis\"] = diagnosis_match.group(1).strip()\n",
    "        \n",
    "        # Extract medications using NER\n",
    "        medications = []\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"MEDICATION\" or ent.label_ == \"CHEMICAL\":\n",
    "                medications.append(ent.text)\n",
    "        sections[\"medications\"] = list(set(medications))  # Remove duplicates\n",
    "        \n",
    "        # Extract other relevant sections...\n",
    "        \n",
    "        return sections\n",
    "    \n",
    "    def _parse_claim_document(self, text: str, doc) -> Dict:\n",
    "        \"\"\"Parse insurance claim document into structured sections\"\"\"\n",
    "        # Implementation for claim documents\n",
    "        sections = {}\n",
    "        \n",
    "        # Extract policy details\n",
    "        policy_info = self._extract_policy_details(text)\n",
    "        sections[\"policy_info\"] = policy_info\n",
    "        \n",
    "        # Extract claim amount details\n",
    "        sections[\"claim_details\"] = self._extract_claim_details(text)\n",
    "        \n",
    "        # Extract dates using NER\n",
    "        dates = {}\n",
    "        date_labels = [\"DATE_ADMISSION\", \"DATE_DISCHARGE\", \"DATE_CLAIM\"]\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"DATE\":\n",
    "                # Try to classify the type of date\n",
    "                context = text[max(0, ent.start_char-30):min(len(text), ent.end_char+30)]\n",
    "                for label in date_labels:\n",
    "                    if label.lower().replace(\"date_\", \"\") in context.lower():\n",
    "                        dates[label.lower().replace(\"date_\", \"\")] = ent.text\n",
    "        sections[\"dates\"] = dates\n",
    "        \n",
    "        return sections\n",
    "    \n",
    "    def _extract_patient_details(self, text: str) -> Dict:\n",
    "        \"\"\"Extract structured patient information\"\"\"\n",
    "        details = {}\n",
    "        \n",
    "        # Extract patient name\n",
    "        name_match = re.search(r\"(?:Name|Patient Name)(?:\\s*:)?\\s*([A-Za-z\\s.]+)\", text)\n",
    "        if name_match:\n",
    "            details[\"name\"] = name_match.group(1).strip()\n",
    "        \n",
    "        # Extract age\n",
    "        age_match = re.search(r\"(?:Age|Years)(?:\\s*:)?\\s*(\\d+)\\s*(?:years|yrs)?\", text)\n",
    "        if age_match:\n",
    "            details[\"age\"] = int(age_match.group(1))\n",
    "        \n",
    "        # Extract gender\n",
    "        gender_match = re.search(r\"(?:Gender|Sex)(?:\\s*:)?\\s*([A-Za-z]+)\", text)\n",
    "        if gender_match:\n",
    "            details[\"gender\"] = gender_match.group(1).strip()\n",
    "        \n",
    "        # Extract contact number\n",
    "        contact_match = re.search(r\"(?:Contact|Phone|Mobile)(?:\\s*:)?\\s*(\\+?\\d[\\d\\s-]{8,})\", text)\n",
    "        if contact_match:\n",
    "            details[\"contact\"] = contact_match.group(1).strip()\n",
    "        \n",
    "        # Extract Aadhaar number (with proper format validation)\n",
    "        aadhaar_match = re.search(r\"(?:Aadhaar|ID|Identity Number)(?:\\s*:)?\\s*(\\d{4}\\s*\\d{4}\\s*\\d{4})\", text)\n",
    "        if aadhaar_match:\n",
    "            details[\"aadhaar\"] = aadhaar_match.group(1).replace(\" \", \"\")\n",
    "        \n",
    "        return details\n",
    "    \n",
    "    def _extract_policy_details(self, text: str) -> Dict:\n",
    "        \"\"\"Extract insurance policy details from text\"\"\"\n",
    "        details = {}\n",
    "        \n",
    "        # Extract policy number\n",
    "        policy_match = re.search(r\"(?:Policy\\sNumber|Policy\\sNo)(?:\\s*:)?\\s*([A-Z0-9-/]+)\", text)\n",
    "        if policy_match:\n",
    "            details[\"policy_number\"] = policy_match.group(1).strip()\n",
    "        \n",
    "        # Extract insurer name\n",
    "        insurer_match = re.search(r\"(?:Insurer|Insurance\\sCompany)(?:\\s*:)?\\s*([A-Za-z\\s.]+)\", text)\n",
    "        if insurer_match:\n",
    "            details[\"insurer\"] = insurer_match.group(1).strip()\n",
    "        \n",
    "        # Extract sum insured\n",
    "        sum_match = re.search(r\"(?:Sum\\sInsured|Coverage\\sAmount)(?:\\s*:)?\\s*(?:Rs\\.?|INR)?\\s*([\\d,]+)\", text)\n",
    "        if sum_match:\n",
    "            # Remove commas and convert to integer\n",
    "            details[\"sum_insured\"] = int(sum_match.group(1).replace(\",\", \"\"))\n",
    "        \n",
    "        return details\n",
    "    \n",
    "    def _extract_claim_details(self, text: str) -> Dict:\n",
    "        \"\"\"Extract claim amount and details\"\"\"\n",
    "        details = {}\n",
    "        \n",
    "        # Extract claimed amount\n",
    "        claimed_match = re.search(r\"(?:Claimed\\sAmount|Total\\sClaim)(?:\\s*:)?\\s*(?:Rs\\.?|INR)?\\s*([\\d,]+)\", text)\n",
    "        if claimed_match:\n",
    "            details[\"claimed_amount\"] = int(claimed_match.group(1).replace(\",\", \"\"))\n",
    "        \n",
    "        # Extract approved amount if available\n",
    "        approved_match = re.search(r\"(?:Approved\\sAmount|Sanctioned\\sAmount)(?:\\s*:)?\\s*(?:Rs\\.?|INR)?\\s*([\\d,]+)\", text)\n",
    "        if approved_match:\n",
    "            details[\"approved_amount\"] = int(approved_match.group(1).replace(\",\", \"\"))\n",
    "        \n",
    "        # Extract claim status\n",
    "        status_match = re.search(r\"(?:Status|Claim\\sStatus)(?:\\s*:)?\\s*([A-Za-z\\s]+)\", text)\n",
    "        if status_match:\n",
    "            details[\"status\"] = status_match.group(1).strip()\n",
    "        \n",
    "        return details\n",
    "\n",
    "\n",
    "class MedicalDocumentSummarizer:\n",
    "    \"\"\"Class for summarizing medical documents\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize the document parser\n",
    "        self.parser = MedicalDocumentParser()\n",
    "        \n",
    "        # Initialize NLP summarization pipeline\n",
    "        self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "        \n",
    "        # Initialize different summary templates\n",
    "        self.templates = {\n",
    "            \"discharge\": self._discharge_summary_template,\n",
    "            \"claim\": self._claim_summary_template,\n",
    "            \"generic\": self._generic_summary_template\n",
    "        }\n",
    "    \n",
    "    def summarize(self, document_text: str, document_type: str = \"discharge\", \n",
    "                  max_length: int = 150, format_type: str = \"plain\") -> str:\n",
    "        \"\"\"\n",
    "        Generate a concise summary of the medical document\n",
    "        \n",
    "        Args:\n",
    "            document_text: Raw text of the medical document\n",
    "            document_type: Type of document (discharge, claim, etc.)\n",
    "            max_length: Maximum length of the detailed summary in tokens\n",
    "            format_type: Output format (plain, html, json)\n",
    "            \n",
    "        Returns:\n",
    "            Formatted summary of the document\n",
    "        \"\"\"\n",
    "        # Parse the document\n",
    "        parsed_doc = self.parser.parse_document(document_text, document_type)\n",
    "        \n",
    "        # Generate template-based summary\n",
    "        if document_type in self.templates:\n",
    "            template_fn = self.templates[document_type]\n",
    "            summary = template_fn(parsed_doc)\n",
    "        else:\n",
    "            summary = self.templates[\"generic\"](parsed_doc)\n",
    "        \n",
    "        # For longer documents, augment with NLP-based summary\n",
    "        if len(document_text) > 1000:\n",
    "            # Extract main body for summarization (excluding headers, patient info)\n",
    "            main_body = self._extract_main_body(document_text)\n",
    "            if main_body:\n",
    "                nlp_summary = self.summarizer(main_body, max_length=max_length)[0]['summary_text']\n",
    "                summary += f\"\\n\\nKey Points:\\n{nlp_summary}\"\n",
    "        \n",
    "        # Format the summary according to requested format\n",
    "        return self._format_summary(summary, format_type)\n",
    "    \n",
    "    def _discharge_summary_template(self, parsed_doc: Dict) -> str:\n",
    "        \"\"\"Create summary from parsed discharge document\"\"\"\n",
    "        summary = \"DISCHARGE SUMMARY\\n\\n\"\n",
    "        \n",
    "        # Add patient information if available\n",
    "        if \"patient_info\" in parsed_doc:\n",
    "            patient = parsed_doc[\"patient_info\"]\n",
    "            summary += f\"Patient: {patient.get('name', 'N/A')}\"\n",
    "            if 'age' in patient and 'gender' in patient:\n",
    "                summary += f\" ({patient.get('age')}Y, {patient.get('gender')})\\n\"\n",
    "            else:\n",
    "                summary += \"\\n\"\n",
    "        \n",
    "        # Add diagnosis if available\n",
    "        if \"diagnosis\" in parsed_doc:\n",
    "            summary += f\"Diagnosis: {parsed_doc['diagnosis']}\\n\"\n",
    "        \n",
    "        # Add medications if available\n",
    "        if \"medications\" in parsed_doc and parsed_doc[\"medications\"]:\n",
    "            summary += f\"Medications: {', '.join(parsed_doc['medications'][:5])}\"\n",
    "            if len(parsed_doc[\"medications\"]) > 5:\n",
    "                summary += f\" and {len(parsed_doc['medications']) - 5} more\"\n",
    "            summary += \"\\n\"\n",
    "        \n",
    "        # Add other important information\n",
    "        if \"treatment\" in parsed_doc:\n",
    "            summary += f\"Treatment: {parsed_doc['treatment']}\\n\"\n",
    "        \n",
    "        if \"follow_up\" in parsed_doc:\n",
    "            summary += f\"Follow-up: {parsed_doc['follow_up']}\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _claim_summary_template(self, parsed_doc: Dict) -> str:\n",
    "        \"\"\"Create summary from parsed claim document\"\"\"\n",
    "        summary = \"INSURANCE CLAIM SUMMARY\\n\\n\"\n",
    "        \n",
    "        # Add patient information\n",
    "        if \"patient_info\" in parsed_doc:\n",
    "            patient = parsed_doc[\"patient_info\"]\n",
    "            summary += f\"Patient: {patient.get('name', 'N/A')}\\n\"\n",
    "        \n",
    "        # Add policy information\n",
    "        if \"policy_info\" in parsed_doc:\n",
    "            policy = parsed_doc[\"policy_info\"]\n",
    "            summary += f\"Policy: {policy.get('policy_number', 'N/A')}\"\n",
    "            if \"insurer\" in policy:\n",
    "                summary += f\" ({policy['insurer']})\"\n",
    "            summary += \"\\n\"\n",
    "            \n",
    "            if \"sum_insured\" in policy:\n",
    "                summary += f\"Coverage: ₹{policy['sum_insured']:,}\\n\"\n",
    "        \n",
    "        # Add claim details\n",
    "        if \"claim_details\" in parsed_doc:\n",
    "            claim = parsed_doc[\"claim_details\"]\n",
    "            if \"claimed_amount\" in claim:\n",
    "                summary += f\"Claimed: ₹{claim['claimed_amount']:,}\\n\"\n",
    "            \n",
    "            if \"approved_amount\" in claim:\n",
    "                summary += f\"Approved: ₹{claim['approved_amount']:,}\\n\"\n",
    "                \n",
    "            if \"status\" in claim:\n",
    "                summary += f\"Status: {claim['status']}\\n\"\n",
    "        \n",
    "        # Add dates\n",
    "        if \"dates\" in parsed_doc:\n",
    "            dates = parsed_doc[\"dates\"]\n",
    "            if \"admission\" in dates:\n",
    "                summary += f\"Admission: {dates['admission']}\\n\"\n",
    "            if \"discharge\" in dates:\n",
    "                summary += f\"Discharge: {dates['discharge']}\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _generic_summary_template(self, parsed_doc: Dict) -> str:\n",
    "        \"\"\"Create a generic summary when document type is unknown\"\"\"\n",
    "        summary = \"MEDICAL DOCUMENT SUMMARY\\n\\n\"\n",
    "        \n",
    "        # Try to extract any available information\n",
    "        for section, content in parsed_doc.items():\n",
    "            if isinstance(content, dict):\n",
    "                summary += f\"{section.replace('_', ' ').title()}:\\n\"\n",
    "                for key, value in content.items():\n",
    "                    if value:  # Only include non-empty values\n",
    "                        summary += f\"  - {key.replace('_', ' ').title()}: {value}\\n\"\n",
    "            elif isinstance(content, list):\n",
    "                summary += f\"{section.replace('_', ' ').title()}: \"\n",
    "                summary += \", \".join(content[:5])\n",
    "                if len(content) > 5:\n",
    "                    summary += f\" and {len(content) - 5} more\"\n",
    "                summary += \"\\n\"\n",
    "            else:\n",
    "                summary += f\"{section.replace('_', ' ').title()}: {content}\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _extract_main_body(self, document_text: str) -> str:\n",
    "        \"\"\"Extract the main body of the document, excluding headers and patient info\"\"\"\n",
    "        # Remove common headers\n",
    "        text = re.sub(r\"DISCHARGE SUMMARY|CLAIM FORM|PATIENT INFORMATION\", \"\", document_text)\n",
    "        \n",
    "        # Try to find the beginning of the main content\n",
    "        # This is usually after patient information section\n",
    "        matches = re.search(r\"(?:HISTORY|DIAGNOSIS|CLINICAL DETAILS|TREATMENT DETAILS)\", text)\n",
    "        if matches:\n",
    "            start_pos = matches.start()\n",
    "            return text[start_pos:]\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _format_summary(self, summary: str, format_type: str) -> str:\n",
    "        \"\"\"Format the summary in different output formats\"\"\"\n",
    "        if format_type == \"plain\":\n",
    "            return summary\n",
    "        \n",
    "        elif format_type == \"html\":\n",
    "            # Convert to HTML format\n",
    "            html = \"<div class='medical-summary'>\\n\"\n",
    "            \n",
    "            # Convert section headers to h2\n",
    "            html += re.sub(r\"^([A-Z\\s]+):?$\", r\"<h2>\\1</h2>\", summary, flags=re.MULTILINE)\n",
    "            \n",
    "            # Convert lines with key-value pairs to formatted paragraphs\n",
    "            html = re.sub(r\"^([\\w\\s]+): (.+)$\", r\"<p><strong>\\1:</strong> \\2</p>\", html, flags=re.MULTILINE)\n",
    "            \n",
    "            # Convert any remaining paragraphs\n",
    "            html = re.sub(r\"^([^<\\n].+)$\", r\"<p>\\1</p>\", html, flags=re.MULTILINE)\n",
    "            \n",
    "            html += \"</div>\"\n",
    "            return html\n",
    "        \n",
    "        elif format_type == \"json\":\n",
    "            # Parse summary into JSON structure\n",
    "            json_data = {}\n",
    "            \n",
    "            # Extract section headers\n",
    "            current_section = \"general\"\n",
    "            json_data[current_section] = {}\n",
    "            \n",
    "            for line in summary.split(\"\\n\"):\n",
    "                # Check if this is a section header\n",
    "                if re.match(r\"^[A-Z\\s]+:?$\", line):\n",
    "                    current_section = line.strip().lower().replace(\" \", \"_\").replace(\":\", \"\")\n",
    "                    json_data[current_section] = {}\n",
    "                # Check if this is a key-value pair\n",
    "                elif \":\" in line:\n",
    "                    parts = line.split(\":\", 1)\n",
    "                    key = parts[0].strip().lower().replace(\" \", \"_\")\n",
    "                    value = parts[1].strip()\n",
    "                    json_data[current_section][key] = value\n",
    "                # Skip empty lines\n",
    "                elif line.strip():\n",
    "                    # This is just text belonging to the current section\n",
    "                    if \"text\" not in json_data[current_section]:\n",
    "                        json_data[current_section][\"text\"] = []\n",
    "                    json_data[current_section][\"text\"].append(line.strip())\n",
    "            \n",
    "            import json\n",
    "            return json.dumps(json_data, indent=2)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported format type: {format_type}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    document_text = \"\"\"\n",
    "    DISCHARGE SUMMARY\n",
    "    \n",
    "    Patient Information:\n",
    "    Name: John Doe\n",
    "    Age: 45 years\n",
    "    Gender: Male\n",
    "    Contact: +91 9876543210\n",
    "    Aadhaar: 1234 5678 9012\n",
    "    \n",
    "    Diagnosis:\n",
    "    Type 2 Diabetes Mellitus with Hypertension\n",
    "    \n",
    "    Treatment Details:\n",
    "    Patient underwent diabetic management and blood pressure control protocol.\n",
    "    Medications prescribed include Metformin 500mg BD, Glimepiride 1mg OD, \n",
    "    and Telmisartan 40mg OD.\n",
    "    \n",
    "    Follow-up:\n",
    "    Review after 2 weeks with fasting blood glucose report and BP monitoring chart.\n",
    "    \"\"\"\n",
    "    \n",
    "    summarizer = MedicalDocumentSummarizer()\n",
    "    \n",
    "    # Generate plain text summary\n",
    "    plain_summary = summarizer.summarize(document_text, document_type=\"discharge\")\n",
    "    print(\"PLAIN TEXT SUMMARY:\")\n",
    "    print(plain_summary)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    \n",
    "    # Generate HTML summary\n",
    "    html_summary = summarizer.summarize(document_text, document_type=\"discharge\", format_type=\"html\")\n",
    "    print(\"HTML SUMMARY:\")\n",
    "    print(html_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAIN TEXT SUMMARY:\n",
      "DISCHARGE SUMMARY\n",
      "\n",
      "Patient: N/A\n",
      "Diagnosis: \n",
      "Medications: Metformin, Glimepiride, Telmisartan\n",
      "Treatment: Details:\n",
      "Follow-up: \n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "HTML SUMMARY:\n",
      "<div class='medical-summary'>\n",
      "<h2>DISCHARGE SUMMARY\n",
      "</h2>\n",
      "<p><strong>Patient:</strong> N/A</p>\n",
      "<p>Diagnosis: </p>\n",
      "<p><strong>Medications:</strong> Metformin, Glimepiride, Telmisartan</p>\n",
      "<p><strong>Treatment:</strong> Details:</p>\n",
      "<p>Follow-up: </p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from typing import Dict, List, Optional\n",
    "from transformers import pipeline\n",
    "import traceback\n",
    "\n",
    "# Try to import spacy and the required model\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "except (ImportError, OSError) as e:\n",
    "    print(\"NLP model loading error: \", str(e))\n",
    "    print(\"\\nTo fix this issue:\")\n",
    "    print(\"1. Make sure spaCy is installed: pip install spacy\")\n",
    "    print(\"2. Download the required model: python -m spacy download en_core_web_md\")\n",
    "    \n",
    "    # Define a fallback for when spaCy isn't available\n",
    "    class DummyNLP:\n",
    "        def __call__(self, text):\n",
    "            class DummyDoc:\n",
    "                def __init__(self):\n",
    "                    self.ents = []\n",
    "            return DummyDoc()\n",
    "    nlp = DummyNLP()\n",
    "\n",
    "\n",
    "class MedicalDocumentParser:\n",
    "    \"\"\"Class for parsing different types of medical documents\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize regex patterns for different document sections\n",
    "        self.section_patterns = {\n",
    "            \"patient_info\": re.compile(r\"(?:Patient Information|Patient Details|Personal Details)(?:\\s*:)?(.*?)(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z)\", re.DOTALL),\n",
    "            \"diagnosis\": re.compile(r\"(?:Diagnosis|Clinical Impression|Assessment)(?:\\s*:)?(.*?)(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z)\", re.DOTALL),\n",
    "            # Add more patterns for other sections\n",
    "        }\n",
    "    \n",
    "    def parse_document(self, document_text: str, document_type: str = \"discharge\") -> Dict:\n",
    "        \"\"\"\n",
    "        Parse the document text into structured sections\n",
    "        \n",
    "        Args:\n",
    "            document_text: Raw text of the medical document\n",
    "            document_type: Type of document (discharge, claim, etc.)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing structured document sections\n",
    "        \"\"\"\n",
    "        # Process document with NLP\n",
    "        try:\n",
    "            doc = nlp(document_text)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: NLP processing failed: {str(e)}\")\n",
    "            doc = None\n",
    "        \n",
    "        # Extract sections based on document type\n",
    "        if document_type == \"discharge\":\n",
    "            return self._parse_discharge_summary(document_text, doc)\n",
    "        elif document_type == \"claim\":\n",
    "            return self._parse_claim_document(document_text, doc)\n",
    "        else:\n",
    "            return self._parse_generic_medical_document(document_text, doc)\n",
    "    \n",
    "    def _parse_discharge_summary(self, text: str, doc) -> Dict:\n",
    "        \"\"\"Parse discharge summary into structured sections\"\"\"\n",
    "        sections = {}\n",
    "        \n",
    "        # Extract patient information\n",
    "        patient_match = self.section_patterns[\"patient_info\"].search(text)\n",
    "        if patient_match:\n",
    "            sections[\"patient_info\"] = self._extract_patient_details(patient_match.group(1))\n",
    "        \n",
    "        # Extract diagnosis\n",
    "        diagnosis_match = self.section_patterns[\"diagnosis\"].search(text)\n",
    "        if diagnosis_match:\n",
    "            sections[\"diagnosis\"] = diagnosis_match.group(1).strip()\n",
    "        \n",
    "        # Extract medications using NER if doc is available\n",
    "        if doc is not None:\n",
    "            medications = []\n",
    "            for ent in doc.ents:\n",
    "                if hasattr(ent, 'label_') and (ent.label_ == \"MEDICATION\" or ent.label_ == \"CHEMICAL\"):\n",
    "                    medications.append(ent.text)\n",
    "            if medications:\n",
    "                sections[\"medications\"] = list(set(medications))  # Remove duplicates\n",
    "        \n",
    "        # Fallback extraction for medications using regex\n",
    "        if \"medications\" not in sections:\n",
    "            med_match = re.search(r\"(?:Medications|Medicine|Drugs)(?:\\s*:)?(.*?)(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z)\", text, re.DOTALL)\n",
    "            if med_match:\n",
    "                # Extract medicine names (basic approach)\n",
    "                med_text = med_match.group(1)\n",
    "                med_list = re.findall(r\"([A-Z][a-z]+(?:\\s[A-Za-z]+)?)\\s+\\d+(?:mg|mcg|ml|g)\", med_text)\n",
    "                if med_list:\n",
    "                    sections[\"medications\"] = med_list\n",
    "        \n",
    "        # Extract treatment information\n",
    "        treatment_match = re.search(r\"(?:Treatment|Procedure|Management)(?:\\s*:)?(.*?)(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z)\", text, re.DOTALL)\n",
    "        if treatment_match:\n",
    "            sections[\"treatment\"] = treatment_match.group(1).strip()\n",
    "        \n",
    "        # Extract follow-up information\n",
    "        followup_match = re.search(r\"(?:Follow[- ]up|Review|Next Visit)(?:\\s*:)?(.*?)(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z)\", text, re.DOTALL)\n",
    "        if followup_match:\n",
    "            sections[\"follow_up\"] = followup_match.group(1).strip()\n",
    "        \n",
    "        return sections\n",
    "    \n",
    "    def _parse_claim_document(self, text: str, doc) -> Dict:\n",
    "        \"\"\"Parse insurance claim document into structured sections\"\"\"\n",
    "        sections = {}\n",
    "        \n",
    "        # Extract policy details\n",
    "        policy_info = self._extract_policy_details(text)\n",
    "        sections[\"policy_info\"] = policy_info\n",
    "        \n",
    "        # Extract claim amount details\n",
    "        sections[\"claim_details\"] = self._extract_claim_details(text)\n",
    "        \n",
    "        # Extract dates using regex\n",
    "        dates = {}\n",
    "        \n",
    "        # Admission date\n",
    "        admission_match = re.search(r\"(?:Admission Date|Date of Admission)(?:\\s*:)?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{1,2}\\s+[A-Za-z]+\\s+\\d{2,4})\", text)\n",
    "        if admission_match:\n",
    "            dates[\"admission\"] = admission_match.group(1)\n",
    "        \n",
    "        # Discharge date\n",
    "        discharge_match = re.search(r\"(?:Discharge Date|Date of Discharge)(?:\\s*:)?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{1,2}\\s+[A-Za-z]+\\s+\\d{2,4})\", text)\n",
    "        if discharge_match:\n",
    "            dates[\"discharge\"] = discharge_match.group(1)\n",
    "        \n",
    "        # Claim submission date\n",
    "        claim_date_match = re.search(r\"(?:Claim Date|Date of Claim|Submission Date)(?:\\s*:)?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{1,2}\\s+[A-Za-z]+\\s+\\d{2,4})\", text)\n",
    "        if claim_date_match:\n",
    "            dates[\"claim_submission\"] = claim_date_match.group(1)\n",
    "        \n",
    "        sections[\"dates\"] = dates\n",
    "        \n",
    "        return sections\n",
    "    \n",
    "    def _parse_generic_medical_document(self, text: str, doc) -> Dict:\n",
    "        \"\"\"Parse any medical document when type is unknown\"\"\"\n",
    "        sections = {}\n",
    "        \n",
    "        # Try to identify the document type first\n",
    "        if re.search(r\"DISCHARGE|SUMMARY|CLINICAL SUMMARY\", text, re.IGNORECASE):\n",
    "            return self._parse_discharge_summary(text, doc)\n",
    "        elif re.search(r\"CLAIM|INSURANCE|REIMBURSEMENT\", text, re.IGNORECASE):\n",
    "            return self._parse_claim_document(text, doc)\n",
    "        \n",
    "        # Generic extraction for common elements\n",
    "        \n",
    "        # Extract patient details\n",
    "        patient_info_patterns = [\n",
    "            r\"(?:PATIENT|PERSONAL) (?:DETAILS|INFORMATION)(?:\\s*:)?(.*?)(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z)\",\n",
    "            r\"(?:Name|Patient)(?:\\s*:)?\\s*([A-Za-z\\s.]+)\"\n",
    "        ]\n",
    "        \n",
    "        for pattern in patient_info_patterns:\n",
    "            match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "            if match:\n",
    "                patient_text = match.group(1) if len(match.groups()) > 0 else \"\"\n",
    "                sections[\"patient_info\"] = self._extract_patient_details(patient_text or text)\n",
    "                break\n",
    "        \n",
    "        # Try to extract medical information\n",
    "        medical_sections = [\n",
    "            (\"diagnosis\", r\"(?:DIAGNOSIS|IMPRESSION|ASSESSMENT)(?:\\s*:)?(.*?)(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z)\"),\n",
    "            (\"treatment\", r\"(?:TREATMENT|PROCEDURE|MANAGEMENT)(?:\\s*:)?(.*?)(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z)\"),\n",
    "            (\"medications\", r\"(?:MEDICATIONS|MEDICINES|DRUGS)(?:\\s*:)?(.*?)(?=\\n\\s*\\n|\\n\\s*[A-Z]|\\Z)\")\n",
    "        ]\n",
    "        \n",
    "        for section_name, pattern in medical_sections:\n",
    "            match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "            if match:\n",
    "                sections[section_name] = match.group(1).strip()\n",
    "        \n",
    "        return sections\n",
    "    \n",
    "    def _extract_patient_details(self, text: str) -> Dict:\n",
    "        \"\"\"Extract structured patient information\"\"\"\n",
    "        details = {}\n",
    "        \n",
    "        # Extract patient name\n",
    "        name_match = re.search(r\"(?:Name|Patient Name)(?:\\s*:)?\\s*([A-Za-z\\s.]+)\", text, re.IGNORECASE)\n",
    "        if name_match:\n",
    "            details[\"name\"] = name_match.group(1).strip()\n",
    "        \n",
    "        # Extract age\n",
    "        age_match = re.search(r\"(?:Age|Years)(?:\\s*:)?\\s*(\\d+)\\s*(?:years|yrs)?\", text, re.IGNORECASE)\n",
    "        if age_match:\n",
    "            details[\"age\"] = int(age_match.group(1))\n",
    "        \n",
    "        # Extract gender\n",
    "        gender_match = re.search(r\"(?:Gender|Sex)(?:\\s*:)?\\s*([A-Za-z]+)\", text, re.IGNORECASE)\n",
    "        if gender_match:\n",
    "            details[\"gender\"] = gender_match.group(1).strip()\n",
    "        \n",
    "        # Extract contact number\n",
    "        contact_match = re.search(r\"(?:Contact|Phone|Mobile)(?:\\s*:)?\\s*(\\+?\\d[\\d\\s-]{8,})\", text, re.IGNORECASE)\n",
    "        if contact_match:\n",
    "            details[\"contact\"] = contact_match.group(1).strip()\n",
    "        \n",
    "        # Extract Aadhaar number (with proper format validation)\n",
    "        aadhaar_match = re.search(r\"(?:Aadhaar|ID|Identity Number)(?:\\s*:)?\\s*(\\d{4}\\s*\\d{4}\\s*\\d{4})\", text, re.IGNORECASE)\n",
    "        if aadhaar_match:\n",
    "            details[\"aadhaar\"] = aadhaar_match.group(1).replace(\" \", \"\")\n",
    "        \n",
    "        return details\n",
    "    \n",
    "    def _extract_policy_details(self, text: str) -> Dict:\n",
    "        \"\"\"Extract insurance policy details from text\"\"\"\n",
    "        details = {}\n",
    "        \n",
    "        # Extract policy number\n",
    "        policy_match = re.search(r\"(?:Policy\\sNumber|Policy\\sNo)(?:\\s*:)?\\s*([A-Z0-9-/]+)\", text, re.IGNORECASE)\n",
    "        if policy_match:\n",
    "            details[\"policy_number\"] = policy_match.group(1).strip()\n",
    "        \n",
    "        # Extract insurer name\n",
    "        insurer_match = re.search(r\"(?:Insurer|Insurance\\sCompany)(?:\\s*:)?\\s*([A-Za-z\\s.]+)\", text, re.IGNORECASE)\n",
    "        if insurer_match:\n",
    "            details[\"insurer\"] = insurer_match.group(1).strip()\n",
    "        \n",
    "        # Extract sum insured\n",
    "        sum_match = re.search(r\"(?:Sum\\sInsured|Coverage\\sAmount)(?:\\s*:)?\\s*(?:Rs\\.?|INR)?\\s*([\\d,]+)\", text, re.IGNORECASE)\n",
    "        if sum_match:\n",
    "            # Remove commas and convert to integer\n",
    "            try:\n",
    "                details[\"sum_insured\"] = int(sum_match.group(1).replace(\",\", \"\"))\n",
    "            except ValueError:\n",
    "                details[\"sum_insured\"] = sum_match.group(1).replace(\",\", \"\")\n",
    "        \n",
    "        return details\n",
    "    \n",
    "    def _extract_claim_details(self, text: str) -> Dict:\n",
    "        \"\"\"Extract claim amount and details\"\"\"\n",
    "        details = {}\n",
    "        \n",
    "        # Extract claimed amount\n",
    "        claimed_match = re.search(r\"(?:Claimed\\sAmount|Total\\sClaim)(?:\\s*:)?\\s*(?:Rs\\.?|INR)?\\s*([\\d,]+)\", text, re.IGNORECASE)\n",
    "        if claimed_match:\n",
    "            try:\n",
    "                details[\"claimed_amount\"] = int(claimed_match.group(1).replace(\",\", \"\"))\n",
    "            except ValueError:\n",
    "                details[\"claimed_amount\"] = claimed_match.group(1).replace(\",\", \"\")\n",
    "        \n",
    "        # Extract approved amount if available\n",
    "        approved_match = re.search(r\"(?:Approved\\sAmount|Sanctioned\\sAmount)(?:\\s*:)?\\s*(?:Rs\\.?|INR)?\\s*([\\d,]+)\", text, re.IGNORECASE)\n",
    "        if approved_match:\n",
    "            try:\n",
    "                details[\"approved_amount\"] = int(approved_match.group(1).replace(\",\", \"\"))\n",
    "            except ValueError:\n",
    "                details[\"approved_amount\"] = approved_match.group(1).replace(\",\", \"\")\n",
    "        \n",
    "        # Extract claim status\n",
    "        status_match = re.search(r\"(?:Status|Claim\\sStatus)(?:\\s*:)?\\s*([A-Za-z\\s]+)\", text, re.IGNORECASE)\n",
    "        if status_match:\n",
    "            details[\"status\"] = status_match.group(1).strip()\n",
    "        \n",
    "        return details\n",
    "\n",
    "\n",
    "class MedicalDocumentSummarizer:\n",
    "    \"\"\"Class for summarizing medical documents\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize the document parser\n",
    "        self.parser = MedicalDocumentParser()\n",
    "        \n",
    "        # Try to initialize NLP summarization pipeline\n",
    "        try:\n",
    "            self.summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "            self.nlp_available = True\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not initialize NLP summarization: {str(e)}\")\n",
    "            print(\"Install required packages with: pip install transformers torch\")\n",
    "            self.nlp_available = False\n",
    "        \n",
    "        # Initialize different summary templates\n",
    "        self.templates = {\n",
    "            \"discharge\": self._discharge_summary_template,\n",
    "            \"claim\": self._claim_summary_template,\n",
    "            \"generic\": self._generic_summary_template\n",
    "        }\n",
    "    \n",
    "    def summarize(self, document_text: str, document_type: str = \"discharge\", \n",
    "                  max_length: int = 150, format_type: str = \"plain\") -> str:\n",
    "        \"\"\"\n",
    "        Generate a concise summary of the medical document\n",
    "        \n",
    "        Args:\n",
    "            document_text: Raw text of the medical document\n",
    "            document_type: Type of document (discharge, claim, etc.)\n",
    "            max_length: Maximum length of the detailed summary in tokens\n",
    "            format_type: Output format (plain, html, json)\n",
    "            \n",
    "        Returns:\n",
    "            Formatted summary of the document\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Parse the document\n",
    "            parsed_doc = self.parser.parse_document(document_text, document_type)\n",
    "            \n",
    "            # Generate template-based summary\n",
    "            if document_type in self.templates:\n",
    "                template_fn = self.templates[document_type]\n",
    "                summary = template_fn(parsed_doc)\n",
    "            else:\n",
    "                summary = self.templates[\"generic\"](parsed_doc)\n",
    "            \n",
    "            # For longer documents, augment with NLP-based summary if available\n",
    "            if len(document_text) > 1000 and self.nlp_available:\n",
    "                try:\n",
    "                    # Extract main body for summarization (excluding headers, patient info)\n",
    "                    main_body = self._extract_main_body(document_text)\n",
    "                    if main_body:\n",
    "                        nlp_summary = self.summarizer(main_body, max_length=max_length)[0]['summary_text']\n",
    "                        summary += f\"\\n\\nKey Points:\\n{nlp_summary}\"\n",
    "                except Exception as e:\n",
    "                    print(f\"NLP summarization failed: {str(e)}\")\n",
    "            \n",
    "            # Format the summary according to requested format\n",
    "            return self._format_summary(summary, format_type)\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error during document summarization: {str(e)}\\n\"\n",
    "            error_msg += traceback.format_exc()\n",
    "            print(error_msg)\n",
    "            return f\"Error: Could not summarize document. {str(e)}\"\n",
    "    \n",
    "    def _discharge_summary_template(self, parsed_doc: Dict) -> str:\n",
    "        \"\"\"Create summary from parsed discharge document\"\"\"\n",
    "        summary = \"DISCHARGE SUMMARY\\n\\n\"\n",
    "        \n",
    "        # Add patient information if available\n",
    "        if \"patient_info\" in parsed_doc:\n",
    "            patient = parsed_doc[\"patient_info\"]\n",
    "            summary += f\"Patient: {patient.get('name', 'N/A')}\"\n",
    "            if 'age' in patient and 'gender' in patient:\n",
    "                summary += f\" ({patient.get('age')}Y, {patient.get('gender')})\\n\"\n",
    "            else:\n",
    "                summary += \"\\n\"\n",
    "        \n",
    "        # Add diagnosis if available\n",
    "        if \"diagnosis\" in parsed_doc:\n",
    "            summary += f\"Diagnosis: {parsed_doc['diagnosis']}\\n\"\n",
    "        \n",
    "        # Add medications if available\n",
    "        if \"medications\" in parsed_doc:\n",
    "            if isinstance(parsed_doc[\"medications\"], list):\n",
    "                medications = parsed_doc[\"medications\"]\n",
    "                summary += f\"Medications: {', '.join(medications[:5])}\"\n",
    "                if len(medications) > 5:\n",
    "                    summary += f\" and {len(medications) - 5} more\"\n",
    "                summary += \"\\n\"\n",
    "            else:\n",
    "                summary += f\"Medications: {parsed_doc['medications']}\\n\"\n",
    "        \n",
    "        # Add other important information\n",
    "        if \"treatment\" in parsed_doc:\n",
    "            summary += f\"Treatment: {parsed_doc['treatment']}\\n\"\n",
    "        \n",
    "        if \"follow_up\" in parsed_doc:\n",
    "            summary += f\"Follow-up: {parsed_doc['follow_up']}\\n\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "    # [Rest of the methods remain unchanged...]\n",
    "    \n",
    "    def _claim_summary_template(self, parsed_doc: Dict) -> str:\n",
    "        \"\"\"Create summary from parsed claim document\"\"\"\n",
    "        summary = \"INSURANCE CLAIM SUMMARY\\n\\n\"\n",
    "        \n",
    "        # Add patient information\n",
    "        if \"patient_info\" in parsed_doc:\n",
    "            patient = parsed_doc[\"patient_info\"]\n",
    "            summary += f\"Patient: {patient.get('name', 'N/A')}\\n\"\n",
    "        \n",
    "        # Add policy information\n",
    "        if \"policy_info\" in parsed_doc:\n",
    "            policy = parsed_doc[\"policy_info\"]\n",
    "            summary += f\"Policy: {policy.get('policy_number', 'N/A')}\"\n",
    "            if \"insurer\" in policy:\n",
    "                summary += f\" ({policy['insurer']})\"\n",
    "            summary += \"\\n\"\n",
    "            \n",
    "            if \"sum_insured\" in policy:\n",
    "                summary += f\"Coverage: ₹{policy['sum_insured']:,}\\n\"\n",
    "        \n",
    "        # Add claim details\n",
    "        if \"claim_details\" in parsed_doc:\n",
    "            claim = parsed_doc[\"claim_details\"]\n",
    "            if \"claimed_amount\" in claim:\n",
    "                summary += f\"Claimed: ₹{claim['claimed_amount']:,}\\n\"\n",
    "            \n",
    "            if \"approved_amount\" in claim:\n",
    "                summary += f\"Approved: ₹{claim['approved_amount']:,}\\n\"\n",
    "                \n",
    "            if \"status\" in claim:\n",
    "                summary += f\"Status: {claim['status']}\\n\"\n",
    "        \n",
    "        # Add dates\n",
    "        if \"dates\" in parsed_doc:\n",
    "            dates = parsed_doc[\"dates\"]\n",
    "            if \"admission\" in dates:\n",
    "                summary += f\"Admission: {dates['admission']}\\n\"\n",
    "            if \"discharge\" in dates:\n",
    "                summary += f\"Discharge: {dates['discharge']}\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _generic_summary_template(self, parsed_doc: Dict) -> str:\n",
    "        \"\"\"Create a generic summary when document type is unknown\"\"\"\n",
    "        summary = \"MEDICAL DOCUMENT SUMMARY\\n\\n\"\n",
    "        \n",
    "        # Try to extract any available information\n",
    "        for section, content in parsed_doc.items():\n",
    "            if isinstance(content, dict):\n",
    "                summary += f\"{section.replace('_', ' ').title()}:\\n\"\n",
    "                for key, value in content.items():\n",
    "                    if value:  # Only include non-empty values\n",
    "                        summary += f\"  - {key.replace('_', ' ').title()}: {value}\\n\"\n",
    "            elif isinstance(content, list):\n",
    "                summary += f\"{section.replace('_', ' ').title()}: \"\n",
    "                summary += \", \".join(content[:5])\n",
    "                if len(content) > 5:\n",
    "                    summary += f\" and {len(content) - 5} more\"\n",
    "                summary += \"\\n\"\n",
    "            else:\n",
    "                summary += f\"{section.replace('_', ' ').title()}: {content}\\n\"\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _extract_main_body(self, document_text: str) -> str:\n",
    "        \"\"\"Extract the main body of the document, excluding headers and patient info\"\"\"\n",
    "        # Remove common headers\n",
    "        text = re.sub(r\"DISCHARGE SUMMARY|CLAIM FORM|PATIENT INFORMATION\", \"\", document_text)\n",
    "        \n",
    "        # Try to find the beginning of the main content\n",
    "        # This is usually after patient information section\n",
    "        matches = re.search(r\"(?:HISTORY|DIAGNOSIS|CLINICAL DETAILS|TREATMENT DETAILS)\", text)\n",
    "        if matches:\n",
    "            start_pos = matches.start()\n",
    "            return text[start_pos:]\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _format_summary(self, summary: str, format_type: str) -> str:\n",
    "        \"\"\"Format the summary in different output formats\"\"\"\n",
    "        if format_type == \"plain\":\n",
    "            return summary\n",
    "        \n",
    "        elif format_type == \"html\":\n",
    "            # Convert to HTML format\n",
    "            html = \"<div class='medical-summary'>\\n\"\n",
    "            \n",
    "            # Convert section headers to h2\n",
    "            html += re.sub(r\"^([A-Z\\s]+):?$\", r\"<h2>\\1</h2>\", summary, flags=re.MULTILINE)\n",
    "            \n",
    "            # Convert lines with key-value pairs to formatted paragraphs\n",
    "            html = re.sub(r\"^([\\w\\s]+): (.+)$\", r\"<p><strong>\\1:</strong> \\2</p>\", html, flags=re.MULTILINE)\n",
    "            \n",
    "            # Convert any remaining paragraphs\n",
    "            html = re.sub(r\"^([^<\\n].+)$\", r\"<p>\\1</p>\", html, flags=re.MULTILINE)\n",
    "            \n",
    "            html += \"</div>\"\n",
    "            return html\n",
    "        \n",
    "        elif format_type == \"json\":\n",
    "            # Parse summary into JSON structure\n",
    "            json_data = {}\n",
    "            \n",
    "            # Extract section headers\n",
    "            current_section = \"general\"\n",
    "            json_data[current_section] = {}\n",
    "            \n",
    "            for line in summary.split(\"\\n\"):\n",
    "                # Check if this is a section header\n",
    "                if re.match(r\"^[A-Z\\s]+:?$\", line):\n",
    "                    current_section = line.strip().lower().replace(\" \", \"_\").replace(\":\", \"\")\n",
    "                    json_data[current_section] = {}\n",
    "                # Check if this is a key-value pair\n",
    "                elif \":\" in line:\n",
    "                    parts = line.split(\":\", 1)\n",
    "                    key = parts[0].strip().lower().replace(\" \", \"_\")\n",
    "                    value = parts[1].strip()\n",
    "                    json_data[current_section][key] = value\n",
    "                # Skip empty lines\n",
    "                elif line.strip():\n",
    "                    # This is just text belonging to the current section\n",
    "                    if \"text\" not in json_data[current_section]:\n",
    "                        json_data[current_section][\"text\"] = []\n",
    "                    json_data[current_section][\"text\"].append(line.strip())\n",
    "            \n",
    "            import json\n",
    "            return json.dumps(json_data, indent=2)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported format type: {format_type}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    document_text = \"\"\"\n",
    "    DISCHARGE SUMMARY\n",
    "    \n",
    "    Patient Information:\n",
    "    Name: John Doe\n",
    "    Age: 45 years\n",
    "    Gender: Male\n",
    "    Contact: +91 9876543210\n",
    "    Aadhaar: 1234 5678 9012\n",
    "    \n",
    "    Diagnosis:\n",
    "    Type 2 Diabetes Mellitus with Hypertension\n",
    "    \n",
    "    Treatment Details:\n",
    "    Patient underwent diabetic management and blood pressure control protocol.\n",
    "    Medications prescribed include Metformin 500mg BD, Glimepiride 1mg OD, \n",
    "    and Telmisartan 40mg OD.\n",
    "    \n",
    "    Follow-up:\n",
    "    Review after 2 weeks with fasting blood glucose report and BP monitoring chart.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        summarizer = MedicalDocumentSummarizer()\n",
    "        \n",
    "        # Generate plain text summary\n",
    "        plain_summary = summarizer.summarize(document_text, document_type=\"discharge\")\n",
    "        print(\"PLAIN TEXT SUMMARY:\")\n",
    "        print(plain_summary)\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "        \n",
    "        # Generate HTML summary\n",
    "        html_summary = summarizer.summarize(document_text, document_type=\"discharge\", format_type=\"html\")\n",
    "        print(\"HTML SUMMARY:\")\n",
    "        print(html_summary)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in example usage: {str(e)}\")\n",
    "        print(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
